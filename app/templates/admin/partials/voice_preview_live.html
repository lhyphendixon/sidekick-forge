<!-- Live Voice Chat Interface with LiveKit Client and Transcripts -->
<div class="flex flex-col h-full">
    <!-- Status Header -->
    <div class="text-center p-4 border-b border-dark-border">
        <div id="connectionStatus" class="flex items-center justify-center gap-2 mb-2">
            <div class="w-3 h-3 rounded-full bg-yellow-500 animate-pulse" id="statusIndicator"></div>
            <span class="text-sm text-dark-text-secondary" id="statusText">Connecting to voice room...</span>
        </div>
        <p class="text-xs text-dark-text-secondary">Room: {{ room_name }}</p>
    </div>
    
    <div class="flex flex-1 overflow-hidden">
        <!-- Left Side: Transcripts -->
        <div class="w-1/2 flex flex-col border-r border-dark-border">
            <div class="p-3 border-b border-dark-border">
                <h3 class="text-sm font-semibold text-dark-text flex items-center gap-2">
                    <svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 10h.01M12 10h.01M16 10h.01M9 16H5a2 2 0 01-2-2V6a2 2 0 012-2h14a2 2 0 012 2v8a2 2 0 01-2 2h-4l-4 4z"></path>
                    </svg>
                    Live Transcript
                    <span id="liveIndicator" class="ml-auto">
                        <span class="flex h-2 w-2">
                            <span class="animate-ping absolute inline-flex h-2 w-2 rounded-full bg-brand-teal opacity-75"></span>
                            <span class="relative inline-flex rounded-full h-2 w-2 bg-brand-teal"></span>
                        </span>
                    </span>
                </h3>
            </div>
            
            <!-- Transcript Messages -->
            <div id="transcriptContainer" class="flex-1 overflow-y-auto p-4 space-y-3">
                <div class="text-center text-dark-text-secondary text-sm py-8">
                    <svg class="w-8 h-8 mx-auto mb-2 opacity-50" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 12h.01M12 12h.01M16 12h.01M21 12c0 4.418-4.03 8-9 8a9.863 9.863 0 01-4.255-.949L3 20l1.395-3.72C3.512 15.042 3 13.574 3 12c0-4.418 4.03-8 9-8s9 3.582 9 8z"></path>
                    </svg>
                    <p>Waiting for conversation to start...</p>
                </div>
            </div>
            
            <!-- Auto-scroll toggle -->
            <div class="p-2 border-t border-dark-border">
                <label class="flex items-center gap-2 text-xs text-dark-text-secondary">
                    <input type="checkbox" id="autoScroll" checked class="rounded border-dark-border text-brand-teal focus:ring-brand-teal">
                    Auto-scroll transcripts
                </label>
            </div>
        </div>
        
        <!-- Right Side: Voice Controls -->
        <div class="w-1/2 flex flex-col p-4">
            <!-- Audio Visualization -->
            <div class="flex-1 flex items-center justify-center">
                <div id="audioContainer" class="text-center">
                    <!-- Microphone Status -->
                    <div class="mb-6">
                        <div id="micIcon" class="w-20 h-20 mx-auto mb-2 text-dark-text-secondary">
                            <svg fill="none" stroke="currentColor" viewBox="0 0 24 24">
                                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"></path>
                            </svg>
                        </div>
                        <p class="text-sm text-dark-text" id="micStatus">Microphone: Checking...</p>
                    </div>
                    
                    <!-- Audio Level Indicator -->
                    <div class="max-w-xs mx-auto mb-4 hidden" id="audioLevelContainer">
                        <div class="h-2 bg-dark-elevated rounded-full overflow-hidden">
                            <div id="audioLevel" class="h-full bg-brand-teal transition-all duration-100 ease-out" style="width: 0%"></div>
                        </div>
                        <p class="text-xs text-dark-text-secondary mt-1">Audio Level</p>
                    </div>
                    
                    <!-- Agent Status -->
                    <div id="agentStatus" class="hidden">
                        <p class="text-sm text-brand-teal mb-2">Agent Connected</p>
                        <p class="text-xs text-dark-text-secondary">{{ agent.name }}</p>
                    </div>
                </div>
            </div>
            
            <!-- Controls -->
            <div class="border-t border-dark-border pt-4">
                <div class="flex justify-center gap-3">
                    <!-- Mute Button -->
                    <button id="muteBtn" 
                            onclick="toggleMute()"
                            class="p-3 rounded-full bg-dark-elevated text-dark-text hover:bg-dark-border transition-all disabled:opacity-50"
                            disabled>
                        <svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"></path>
                        </svg>
                    </button>
                    
                    <!-- Disconnect Button -->
                    <button id="disconnectBtn"
                            hx-post="/admin/agents/preview/{{ client_id }}/{{ agent_slug }}/voice-stop"
                            hx-vals='{"session_id": "{{ session_id }}", "room_name": "{{ room_name }}"}'
                            hx-target="#voiceStatus"
                            hx-swap="innerHTML"
                            onclick="disconnectVoice()"
                            class="px-4 py-2 bg-brand-salmon text-white rounded-lg hover:bg-brand-salmon/90 transition-all flex items-center gap-2">
                        <svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"></path>
                        </svg>
                        Disconnect
                    </button>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
// Transcript Management
let transcriptEventSource = null;
let autoScroll = true;
const transcriptContainer = document.getElementById('transcriptContainer');
const autoScrollCheckbox = document.getElementById('autoScroll');

// Configure auto-scroll
autoScrollCheckbox.addEventListener('change', (e) => {
    autoScroll = e.target.checked;
});

// Function to add a transcript message
function addTranscript(data) {
    const container = document.getElementById('transcriptContainer');
    
    // Clear placeholder if it exists
    const placeholder = container.querySelector('.text-center');
    if (placeholder) {
        placeholder.remove();
    }
    
    // Create message element
    const messageDiv = document.createElement('div');
    messageDiv.className = `flex gap-3 ${data.role === 'user' ? 'justify-start' : 'justify-end'}`;
    
    // Message content
    const contentDiv = document.createElement('div');
    contentDiv.className = `max-w-[80%] ${data.role === 'user' ? 'order-2' : 'order-1'}`;
    
    // Role indicator
    const roleDiv = document.createElement('div');
    roleDiv.className = `text-xs font-medium mb-1 ${data.role === 'user' ? 'text-dark-text-secondary' : 'text-brand-teal'}`;
    roleDiv.textContent = data.role === 'user' ? 'You' : '{{ agent.name }}';
    
    // Message bubble
    const bubbleDiv = document.createElement('div');
    bubbleDiv.className = `px-4 py-2 rounded-lg ${
        data.role === 'user' 
            ? 'bg-dark-elevated text-dark-text' 
            : 'bg-brand-teal/20 text-dark-text border border-brand-teal/30'
    }`;
    bubbleDiv.textContent = data.content || data.transcript;
    
    // Add citations if available (for assistant messages)
    if (data.role === 'assistant' && data.citations && data.citations.length > 0) {
        const citationsDiv = document.createElement('div');
        citationsDiv.className = 'mt-2 pt-2 border-t border-brand-teal/20';
        citationsDiv.innerHTML = `
            <div class="text-xs text-dark-text-secondary">
                <span class="font-medium">Sources:</span>
                ${data.citations.map((c, i) => `
                    <a href="${c.source_url || '#'}" 
                       class="text-brand-teal hover:underline ml-1" 
                       target="_blank">[${i + 1}]</a>
                `).join('')}
            </div>
        `;
        bubbleDiv.appendChild(citationsDiv);
    }
    
    // Timestamp
    const timeDiv = document.createElement('div');
    timeDiv.className = 'text-xs text-dark-text-secondary mt-1';
    const time = new Date(data.created_at || Date.now());
    timeDiv.textContent = time.toLocaleTimeString();
    
    // Assemble message
    contentDiv.appendChild(roleDiv);
    contentDiv.appendChild(bubbleDiv);
    contentDiv.appendChild(timeDiv);
    
    // Avatar
    const avatarDiv = document.createElement('div');
    avatarDiv.className = `w-8 h-8 rounded-full flex items-center justify-center ${
        data.role === 'user' ? 'order-1 bg-dark-elevated' : 'order-2 bg-brand-teal/20'
    }`;
    avatarDiv.innerHTML = data.role === 'user' 
        ? '<svg class="w-4 h-4 text-dark-text-secondary" fill="currentColor" viewBox="0 0 20 20"><path fill-rule="evenodd" d="M10 9a3 3 0 100-6 3 3 0 000 6zm-7 9a7 7 0 1114 0H3z" clip-rule="evenodd"></path></svg>'
        : '<svg class="w-4 h-4 text-brand-teal" fill="currentColor" viewBox="0 0 20 20"><path d="M2 10a8 8 0 018-8v8h8a8 8 0 11-16 0z"></path></svg>';
    
    messageDiv.appendChild(avatarDiv);
    messageDiv.appendChild(contentDiv);
    
    container.appendChild(messageDiv);
    
    // Auto-scroll if enabled
    if (autoScroll) {
        container.scrollTop = container.scrollHeight;
    }
}

// Function to start transcript streaming
function startTranscriptStream() {
    const conversationId = '{{ conversation_id or "" }}';
    const clientId = '{{ client_id }}';
    const agentId = '{{ agent_id or agent.id }}';
    
    if (!conversationId) {
        console.warn('No conversation ID available for transcript streaming');
        return;
    }
    
    const url = `/api/v1/voice-transcripts/stream?conversation_id=${conversationId}&client_id=${clientId}&agent_id=${agentId}`;
    
    transcriptEventSource = new EventSource(url);
    
    transcriptEventSource.onmessage = (event) => {
        try {
            const data = JSON.parse(event.data);
            if (!data.error) {
                addTranscript(data);
            }
        } catch (e) {
            console.error('Error parsing transcript:', e);
        }
    };
    
    transcriptEventSource.onerror = (error) => {
        console.error('Transcript stream error:', error);
        if (transcriptEventSource.readyState === EventSource.CLOSED) {
            console.log('Transcript stream closed, attempting to reconnect...');
            setTimeout(startTranscriptStream, 5000);
        }
    };
    
    console.log('Started transcript streaming for conversation:', conversationId);
}

// Function to stop transcript streaming
function stopTranscriptStream() {
    if (transcriptEventSource) {
        transcriptEventSource.close();
        transcriptEventSource = null;
        console.log('Stopped transcript streaming');
    }
}

// Wrap entire LiveKit script in IIFE to avoid global conflicts
(function() {
    // Clean up any existing connections before starting
    if (window.livekitRoom && window.livekitRoom.state !== 'disconnected') {
        console.log('ðŸ§¹ Cleaning up existing LiveKit connection...');
        try {
            window.livekitRoom.disconnect();
        } catch (e) {
            console.warn('Error cleaning up room:', e);
        }
        window.livekitRoom = null;
    }

    // Ensure LiveKit SDK is loaded
    if (!window.LivekitClient && !document.querySelector('script[src*="livekit-client"]')) {
        const script = document.createElement('script');
        script.src = '/static/livekit-client.min.js';
        script.onload = () => {
            console.log('LiveKit SDK loaded dynamically');
            window.LiveKitSDK = window.LivekitClient;
            window.livekitSDKLoaded = true;
        };
        script.onerror = () => {
            console.error('Failed to load LiveKit SDK');
            window.livekitSDKLoaded = false;
            updateStatus('error', 'Failed to load LiveKit SDK');
        };
        document.head.appendChild(script);
    } else if (window.LivekitClient) {
        console.log('LiveKit SDK already loaded');
        window.LiveKitSDK = window.LiveKitSDK || window.LivekitClient;
        window.livekitSDKLoaded = true;
    }

    // Add LiveKit CSS if not present
    if (!document.querySelector('link[href*="livekit-client.css"]')) {
        const css = document.createElement('link');
        css.rel = 'stylesheet';
        css.href = '/static/livekit-client.css';
        document.head.appendChild(css);
    }

    // Store server URL and token in window
    window.LIVEKIT_URL = '{{ server_url }}';
    window.LIVEKIT_TOKEN = '{{ user_token }}';
    window.ROOM_NAME = '{{ room_name }}';

    // Update UI status
    function updateStatus(state, message) {
        const statusIndicator = document.getElementById('statusIndicator');
        const statusText = document.getElementById('statusText');
        
        if (!statusIndicator || !statusText) return;
        
        statusText.textContent = message;
        
        switch(state) {
            case 'connecting':
                statusIndicator.className = 'w-3 h-3 rounded-full bg-yellow-500 animate-pulse';
                break;
            case 'connected':
                statusIndicator.className = 'w-3 h-3 rounded-full bg-green-500';
                break;
            case 'error':
                statusIndicator.className = 'w-3 h-3 rounded-full bg-red-500';
                break;
            case 'disconnected':
                statusIndicator.className = 'w-3 h-3 rounded-full bg-gray-500';
                break;
        }
    }

    // Microphone control functions
    window.toggleMute = function() {
        if (!window.livekitRoom) return;
        
        const localParticipant = window.livekitRoom.localParticipant;
        const audioTracks = localParticipant.audioTracks;
        
        audioTracks.forEach(publication => {
            if (publication.track) {
                const newMuted = !publication.track.isMuted;
                publication.track.mute(newMuted);
                updateMuteButton(newMuted);
                console.log(newMuted ? 'ðŸ”‡ Microphone muted' : 'ðŸŽ¤ Microphone unmuted');
            }
        });
    };

    function updateMuteButton(isMuted) {
        const muteBtn = document.getElementById('muteBtn');
        if (!muteBtn) return;
        
        if (isMuted) {
            muteBtn.innerHTML = '<svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5.586 15L4.172 16.414A2 2 0 003 18.828V21a1 1 0 001 1h3.172a2 2 0 001.414-.586L15 15m2 2l5.586-5.586A2 2 0 0024 8.172V5a1 1 0 00-1-1h-3.172a2 2 0 00-1.414.586L13 10"></path></svg>';
            muteBtn.classList.add('bg-red-500', 'hover:bg-red-600');
            muteBtn.classList.remove('bg-dark-elevated', 'hover:bg-dark-border');
        } else {
            muteBtn.innerHTML = '<svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"></path></svg>';
            muteBtn.classList.remove('bg-red-500', 'hover:bg-red-600');
            muteBtn.classList.add('bg-dark-elevated', 'hover:bg-dark-border');
        }
    }

    window.disconnectVoice = function() {
        if (window.livekitRoom) {
            console.log('ðŸ‘‹ Disconnecting from voice room...');
            try {
                window.livekitRoom.disconnect();
                updateStatus('disconnected', 'Disconnected');
            } catch (e) {
                console.error('Error disconnecting:', e);
            }
        }
        // Stop transcript streaming when disconnecting
        stopTranscriptStream();
    };

    // Main connect function
    window.connectToRoom = async function() {
        console.log('ðŸš€ Starting LiveKit connection...');
        updateStatus('connecting', 'Connecting to voice room...');
        
        // Wait for SDK to load
        let attempts = 0;
        while (!window.livekitSDKLoaded && attempts < 50) {
            await new Promise(resolve => setTimeout(resolve, 100));
            attempts++;
        }
        
        if (!window.livekitSDKLoaded || !window.LiveKitSDK) {
            console.error('LiveKit SDK not loaded after 5 seconds');
            updateStatus('error', 'Failed to load voice components');
            return;
        }
        
        const LiveKit = window.LiveKitSDK;
        
        try {
            const room = new LiveKit.Room({
                adaptiveStream: true,
                dynacast: true,
                videoCaptureDefaults: {
                    resolution: { width: 1280, height: 720 },
                    frameRate: 30,
                },
                audioCaptureDefaults: {
                    autoGainControl: true,
                    echoCancellation: true,
                    noiseSuppression: true,
                    sampleRate: 48000,
                    channelCount: 1,
                },
                publishDefaults: {
                    audioPreset: LiveKit.AudioPresets.speech,
                    simulcast: false,
                    stopMicTrackOnMute: false,
                },
            });
            
            window.livekitRoom = room;
            
            // Event handlers
            room.on(LiveKit.RoomEvent.Connected, () => {
                console.log('âœ… Connected to room:', room.name);
                updateStatus('connected', 'Connected to voice room');
                document.getElementById('muteBtn').disabled = false;
                
                // Start transcript streaming when connected
                startTranscriptStream();
            });
            
            room.on(LiveKit.RoomEvent.Disconnected, (reason) => {
                console.log('ðŸ”Œ Disconnected from room:', reason);
                updateStatus('disconnected', 'Disconnected from voice room');
                document.getElementById('muteBtn').disabled = true;
                
                // Stop transcript streaming when disconnected
                stopTranscriptStream();
            });
            
            room.on(LiveKit.RoomEvent.ParticipantConnected, (participant) => {
                console.log('ðŸ‘¤ Participant connected:', participant.identity);
                if (participant.identity.includes('agent')) {
                    document.getElementById('agentStatus').classList.remove('hidden');
                }
            });
            
            room.on(LiveKit.RoomEvent.ParticipantDisconnected, (participant) => {
                console.log('ðŸ‘¤ Participant disconnected:', participant.identity);
                if (participant.identity.includes('agent')) {
                    document.getElementById('agentStatus').classList.add('hidden');
                }
            });
            
            room.on(LiveKit.RoomEvent.TrackSubscribed, (track, publication, participant) => {
                console.log('ðŸŽµ Track subscribed:', track.kind, 'from', participant.identity);
                
                if (track.kind === 'audio') {
                    // Create an audio element and attach the track
                    const audioElement = track.attach();
                    audioElement.autoplay = true;
                    audioElement.style.display = 'none';
                    document.body.appendChild(audioElement);
                    
                    // Store reference for cleanup
                    if (!window.audioElements) window.audioElements = [];
                    window.audioElements.push(audioElement);
                    
                    console.log('ðŸ”Š Audio track attached and playing');
                }
            });
            
            room.on(LiveKit.RoomEvent.TrackUnsubscribed, (track) => {
                console.log('ðŸ”‡ Track unsubscribed:', track.kind);
                track.detach();
            });
            
            room.on(LiveKit.RoomEvent.LocalTrackPublished, (publication) => {
                console.log('ðŸ“¤ Local track published:', publication.trackName);
                document.getElementById('micStatus').textContent = 'Microphone: Active';
                document.getElementById('audioLevelContainer').classList.remove('hidden');
            });
            
            room.on(LiveKit.RoomEvent.LocalTrackUnpublished, (publication) => {
                console.log('ðŸ“¤ Local track unpublished:', publication.trackName);
                document.getElementById('micStatus').textContent = 'Microphone: Inactive';
                document.getElementById('audioLevelContainer').classList.add('hidden');
            });
            
            room.on(LiveKit.RoomEvent.AudioPlaybackStatusChanged, () => {
                if (room.canPlaybackAudio) {
                    console.log('ðŸ”Š Audio playback enabled');
                } else {
                    console.log('ðŸ”‡ Audio playback disabled - user interaction may be required');
                }
            });
            
            room.on(LiveKit.RoomEvent.MediaDevicesError, (error) => {
                console.error('ðŸŽ¤ Media device error:', error);
                updateStatus('error', 'Microphone access denied or unavailable');
                document.getElementById('micStatus').textContent = 'Microphone: Error';
            });
            
            room.on(LiveKit.RoomEvent.ConnectionQualityChanged, (quality, participant) => {
                if (participant === room.localParticipant) {
                    console.log('ðŸ“¶ Connection quality:', quality);
                }
            });
            
            // Audio level monitoring for local participant
            room.on(LiveKit.RoomEvent.LocalAudioLevelChanged, (level) => {
                const audioLevel = document.getElementById('audioLevel');
                if (audioLevel) {
                    const percentage = Math.min(100, level * 100);
                    audioLevel.style.width = percentage + '%';
                }
            });
            
            // Connect to room
            console.log('ðŸ”— Connecting to LiveKit URL:', window.LIVEKIT_URL);
            console.log('ðŸŽ« Using token for room:', window.ROOM_NAME);
            
            await room.connect(window.LIVEKIT_URL, window.LIVEKIT_TOKEN);
            
            // Publish microphone
            try {
                await room.localParticipant.setMicrophoneEnabled(true);
                console.log('ðŸŽ¤ Microphone enabled and publishing');
            } catch (e) {
                console.error('Failed to enable microphone:', e);
                document.getElementById('micStatus').textContent = 'Microphone: Failed to enable';
            }
            
            // Start audio playback
            try {
                await room.startAudio();
                console.log('ðŸ”Š Audio playback started');
            } catch (e) {
                console.log('âš ï¸ Could not start audio playback automatically - user interaction required');
            }
            
        } catch (error) {
            console.error('âŒ Failed to connect:', error);
            updateStatus('error', 'Failed to connect to voice room');
        }
    };

    // Auto-connect on load
    if (window.LIVEKIT_URL && window.LIVEKIT_TOKEN) {
        console.log('ðŸŽ¬ Auto-connecting to room...');
        setTimeout(() => {
            connectToRoom();
        }, 500);
    } else {
        console.error('Missing LiveKit configuration');
        updateStatus('error', 'Missing voice configuration');
    }
})();

// Handle cleanup when leaving page
window.addEventListener('beforeunload', function() {
    if (window.livekitRoom && window.livekitRoom.state === 'connected') {
        console.log('ðŸ§¹ Page unload - disconnecting from LiveKit...');
        try {
            window.livekitRoom.disconnect();
        } catch (e) {
            console.warn('Error during cleanup:', e);
        }
    }
    // Stop transcript streaming
    stopTranscriptStream();
});

// Also handle page visibility changes
document.addEventListener('visibilitychange', function() {
    // Log but don't disconnect when tab becomes hidden
    if (document.hidden && window.livekitRoom && window.livekitRoom.state === 'connected') {
        console.log('ðŸ“± Tab hidden but keeping LiveKit connection alive');
    }
});

// Handle HTMX navigation away from this page
document.body.addEventListener('htmx:beforeSwap', function(evt) {
    if (window.livekitRoom && window.livekitRoom.state !== 'disconnected') {
        console.log('ðŸ”„ HTMX navigation detected, disconnecting LiveKit...');
        try {
            window.livekitRoom.disconnect();
        } catch (e) {
            console.warn('Error during HTMX cleanup:', e);
        }
    }
    // Stop transcript streaming
    stopTranscriptStream();
});

// Start transcript stream immediately if we have the conversation ID
if ('{{ conversation_id }}') {
    console.log('Starting transcript stream for conversation: {{ conversation_id }}');
    // Wait a bit for the page to be fully loaded
    setTimeout(startTranscriptStream, 1000);
}
</script>