<!-- Live Voice Chat Interface with LiveKit Client and Transcripts -->
<div class="flex flex-col h-full">
    <!-- Status slot (used by HTMX swaps when ending the session) -->
    <div id="voiceStatus" class="hidden"></div>

    <!-- Status Header -->
    <div class="text-center p-4 border-b border-dark-border">
        <div id="connectionStatus" class="flex items-center justify-center gap-2 mb-2">
            <div class="w-3 h-3 rounded-full bg-yellow-500 animate-pulse" id="statusIndicator"></div>
            <span class="text-sm text-dark-text-secondary" id="statusText">Connecting to voice room...</span>
        </div>
        <p class="text-xs text-dark-text-secondary">Room: {{ room_name }}</p>
    </div>
    
    <div class="flex flex-1 overflow-hidden">
        <!-- Left Side: Transcripts -->
        <div class="w-1/2 flex flex-col border-r border-dark-border">
            <div class="p-3 border-b border-dark-border flex items-center gap-2">
                <h3 class="text-sm font-semibold text-dark-text flex items-center gap-2">
                    <svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 10h.01M12 10h.01M16 10h.01M9 16H5a2 2 0 01-2-2V6a2 2 0 012-2h14a2 2 0 012 2v8a2 2 0 01-2 2h-4l-4 4z"></path>
                    </svg>
                    Live Transcript
                    <span id="liveIndicator" class="ml-auto">
                        <span class="flex h-2 w-2">
                            <span class="animate-ping absolute inline-flex h-2 w-2 rounded-full bg-brand-teal opacity-75"></span>
                            <span class="relative inline-flex rounded-full h-2 w-2 bg-brand-teal"></span>
                        </span>
                    </span>
                </h3>
                <button id="loadHistoryBtn" class="ml-auto px-2 py-1 text-xs border border-dark-border rounded hover:bg-dark-elevated" onclick="loadTranscriptHistory()" title="Fetch transcript history now">Load history</button>
            </div>
            
            <!-- Transcript Messages -->
            <div id="transcriptContainer" class="flex-1 overflow-y-auto p-4 space-y-3">
                <div class="text-center text-dark-text-secondary text-sm py-8">
                    <svg class="w-8 h-8 mx-auto mb-2 opacity-50" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 12h.01M12 12h.01M16 12h.01M21 12c0 4.418-4.03 8-9 8a9.863 9.863 0 01-4.255-.949L3 20l1.395-3.72C3.512 15.042 3 13.574 3 12c0-4.418 4.03-8 9-8s9 3.582 9 8z"></path>
                    </svg>
                    <p>Waiting for conversation to start...</p>
                </div>
            </div>
            
            <!-- Auto-scroll toggle -->
            <div class="p-2 border-t border-dark-border">
                <label class="flex items-center gap-2 text-xs text-dark-text-secondary">
                    <input type="checkbox" id="autoScroll" checked class="rounded border-dark-border text-brand-teal focus:ring-brand-teal">
                    Auto-scroll transcripts
                </label>
            </div>
        </div>
        
        <!-- Right Side: Voice Controls -->
        <div class="w-1/2 flex flex-col p-4">
            <!-- Audio Visualization -->
            <div class="flex-1 flex items-center justify-center">
                <div id="audioContainer" class="text-center">
                    <!-- Microphone Status -->
                    <div class="mb-6">
                        <div id="micIcon" class="w-20 h-20 mx-auto mb-2 text-dark-text-secondary">
                            <svg fill="none" stroke="currentColor" viewBox="0 0 24 24">
                                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"></path>
                            </svg>
                        </div>
                        <p class="text-sm text-dark-text" id="micStatus">Microphone: Checking...</p>
                    </div>
                    
                    <!-- Audio Level Indicator -->
                    <div class="max-w-xs mx-auto mb-4 hidden" id="audioLevelContainer">
                        <div class="h-2 bg-dark-elevated rounded-full overflow-hidden">
                            <div id="audioLevel" class="h-full bg-brand-teal transition-all duration-100 ease-out" style="width: 0%"></div>
                        </div>
                        <p class="text-xs text-dark-text-secondary mt-1">Audio Level</p>
                    </div>
                    
                    <!-- Agent Status -->
                    <div id="agentStatus" class="hidden">
                        <p class="text-sm text-brand-teal mb-2">Agent Connected</p>
                        <p class="text-xs text-dark-text-secondary">{{ agent.name }}</p>
                    </div>
                </div>
            </div>
            
            <!-- Controls -->
            <div class="border-t border-dark-border pt-4">
                <div id="audioPermissionBanner" class="hidden mb-3 p-3 rounded border border-brand-teal/40 bg-brand-teal/10 text-sm text-dark-text">
                    <p class="font-medium mb-1">Audio playback blocked</p>
                    <p class="text-xs text-dark-text-secondary">Click below to enable audio so you can hear the assistant.</p>
                    <button id="enableAudioBtn" class="mt-3 btn-primary px-3 py-2 rounded text-xs font-medium">Enable Audio</button>
                </div>
                <div id="gestureHint" class="hidden mb-3 px-3 py-2 rounded border border-brand-teal/30 bg-brand-teal/10 text-xs text-dark-text text-center">
                    Tap start to allow microphone access.
                </div>
                <button id="startVoiceBtn" class="hidden w-full mb-3 px-4 py-2 rounded-lg bg-brand-teal text-white text-sm font-medium hover:bg-brand-teal/90 transition-all">
                    Start Voice Session
                </button>
                <div class="flex justify-center gap-3">
                    <!-- Mute Button -->
                    <button id="muteBtn" 
                            onclick="toggleMute()"
                            class="p-3 rounded-full bg-dark-elevated text-dark-text hover:bg-dark-border transition-all disabled:opacity-50"
                            disabled>
                        <svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"></path>
                        </svg>
                    </button>
                    
                    <!-- Disconnect Button -->
                    <button id="disconnectBtn"
                            hx-post="/admin/agents/preview/{{ client_id }}/{{ agent_slug }}/voice-stop"
                            hx-vals='{"session_id": "{{ session_id }}", "room_name": "{{ room_name }}"}'
                            hx-target="#voiceStatus"
                            hx-swap="innerHTML"
                            onclick="disconnectVoice()"
                            class="px-4 py-2 bg-brand-salmon text-white rounded-lg hover:bg-brand-salmon/90 transition-all flex items-center gap-2">
                        <svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"></path>
                        </svg>
                        Disconnect
                    </button>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
// Transcript Management
let transcriptEventSource = null;
let autoScroll = true;
const transcriptContainer = document.getElementById('transcriptContainer');
const autoScrollCheckbox = document.getElementById('autoScroll');

// Configure auto-scroll
autoScrollCheckbox.addEventListener('change', (e) => {
    autoScroll = e.target.checked;
});

// Function to add a transcript message
function addTranscript(data) {
    const container = document.getElementById('transcriptContainer');
    
    // Clear placeholder if it exists
    const placeholder = container.querySelector('.text-center');
    if (placeholder) {
        placeholder.remove();
    }
    
    // Create message element
    const messageDiv = document.createElement('div');
    messageDiv.className = `flex gap-3 ${data.role === 'user' ? 'justify-start' : 'justify-end'}`;
    
    // Message content
    const contentDiv = document.createElement('div');
    contentDiv.className = `max-w-[80%] ${data.role === 'user' ? 'order-2' : 'order-1'}`;
    
    // Role indicator
    const roleDiv = document.createElement('div');
    roleDiv.className = `text-xs font-medium mb-1 ${data.role === 'user' ? 'text-dark-text-secondary' : 'text-brand-teal'}`;
    roleDiv.textContent = data.role === 'user' ? 'You' : '{{ agent.name }}';
    
    // Message bubble
    const bubbleDiv = document.createElement('div');
    bubbleDiv.className = `px-4 py-2 rounded-lg ${
        data.role === 'user' 
            ? 'bg-dark-elevated text-dark-text' 
            : 'bg-brand-teal/20 text-dark-text border border-brand-teal/30'
    }`;
    bubbleDiv.textContent = data.content || data.transcript;
    
    // Add citations if available (for assistant messages)
    if (data.role === 'assistant' && data.citations && data.citations.length > 0) {
        const citationsDiv = document.createElement('div');
        citationsDiv.className = 'mt-2 pt-2 border-t border-brand-teal/20';
        citationsDiv.innerHTML = `
            <div class="text-xs text-dark-text-secondary">
                <span class="font-medium">Sources:</span>
                ${data.citations.map((c, i) => `
                    <a href="${c.source_url || '#'}" 
                       class="text-brand-teal hover:underline ml-1" 
                       target="_blank">[${i + 1}]</a>
                `).join('')}
            </div>
        `;
        bubbleDiv.appendChild(citationsDiv);
    }
    
    // Timestamp
    const timeDiv = document.createElement('div');
    timeDiv.className = 'text-xs text-dark-text-secondary mt-1';
    const time = new Date(data.created_at || Date.now());
    timeDiv.textContent = time.toLocaleTimeString();
    
    // Assemble message
    contentDiv.appendChild(roleDiv);
    contentDiv.appendChild(bubbleDiv);
    contentDiv.appendChild(timeDiv);
    
    // Avatar
    const avatarDiv = document.createElement('div');
    avatarDiv.className = `w-8 h-8 rounded-full flex items-center justify-center ${
        data.role === 'user' ? 'order-1 bg-dark-elevated' : 'order-2 bg-brand-teal/20'
    }`;
    avatarDiv.innerHTML = data.role === 'user' 
        ? '<svg class="w-4 h-4 text-dark-text-secondary" fill="currentColor" viewBox="0 0 20 20"><path fill-rule="evenodd" d="M10 9a3 3 0 100-6 3 3 0 000 6zm-7 9a7 7 0 1114 0H3z" clip-rule="evenodd"></path></svg>'
        : '<svg class="w-4 h-4 text-brand-teal" fill="currentColor" viewBox="0 0 20 20"><path d="M2 10a8 8 0 018-8v8h8a8 8 0 11-16 0z"></path></svg>';
    
    messageDiv.appendChild(avatarDiv);
    messageDiv.appendChild(contentDiv);
    
    container.appendChild(messageDiv);
    
    // Auto-scroll if enabled
    if (autoScroll) {
        container.scrollTop = container.scrollHeight;
    }
}

// Function to start transcript streaming
function startTranscriptStream() {
    const conversationId = '{{ conversation_id or "" }}';
    const clientId = '{{ client_id }}';
    const agentId = '{{ agent_id or agent.id }}';
    
    try { if (transcriptEventSource) { transcriptEventSource.close(); } } catch (e) {}
    transcriptEventSource = null;
    
    // Ensure only one SSE connection is active
    try {
        if (transcriptEventSource) { transcriptEventSource.close(); }
    } catch (e) { /* ignore */ }
    transcriptEventSource = null;

    if (!conversationId) {
        console.warn('No conversation ID available for transcript streaming');
        return;
    }
    
    const url = `/api/v1/voice-transcripts/stream?conversation_id=${conversationId}&client_id=${clientId}&agent_id=${agentId}&include_citations=true`;
    
    transcriptEventSource = new EventSource(url);
    
    transcriptEventSource.onmessage = (event) => {
        try {
            const data = JSON.parse(event.data);
            if (!data.error) {
                addTranscript(data);
            }
        } catch (e) {
            console.error('Error parsing transcript:', e);
        }
    };
    
    transcriptEventSource.onerror = (error) => {
        console.error('Transcript stream error:', error);
        if (transcriptEventSource.readyState === EventSource.CLOSED) {
            console.log('Transcript stream closed, attempting to reconnect...');
            setTimeout(startTranscriptStream, 5000);
        }
    };
    
    console.log('Started transcript streaming for conversation:', conversationId);
}

async function loadTranscriptHistory() {
    try {
        const conversationId = '{{ conversation_id or "" }}';
        const clientId = '{{ client_id }}';
        if (!conversationId || !clientId) { console.warn('Missing ids for history'); return; }
        const url = `/api/v1/voice-transcripts/history?conversation_id=${conversationId}&client_id=${clientId}&limit=50&include_citations=true`;
        const res = await fetch(url);
        if (!res.ok) { console.warn('History fetch failed', res.status); return; }
        const payload = await res.json();
        if (payload && payload.success && Array.isArray(payload.data)) {
            payload.data.forEach(addTranscript);
        }
    } catch (e) { console.warn('History fetch error', e); }
}

// Function to stop transcript streaming
function stopTranscriptStream() {
    if (transcriptEventSource) {
        transcriptEventSource.close();
        transcriptEventSource = null;
        console.log('Stopped transcript streaming');
    }
}

// Wrap entire LiveKit script in IIFE to avoid global conflicts
(function() {
    // Clean up any existing connections before starting
    if (window.livekitRoom && window.livekitRoom.state !== 'disconnected') {
        console.log('ðŸ§¹ Cleaning up existing LiveKit connection...');
        try {
            window.livekitRoom.disconnect();
        } catch (e) {
            console.warn('Error cleaning up room:', e);
        }
        window.livekitRoom = null;
    }

    // Ensure LiveKit SDK is loaded
    if (!window.LivekitClient && !document.querySelector('script[src*="livekit-client"]')) {
        const script = document.createElement('script');
        script.src = '/static/livekit-client.min.js';
        script.onload = () => {
            console.log('LiveKit SDK loaded dynamically');
            window.LiveKitSDK = window.LivekitClient;
            window.livekitSDKLoaded = true;
        };
        script.onerror = () => {
            console.error('Failed to load LiveKit SDK');
            window.livekitSDKLoaded = false;
            updateStatus('error', 'Failed to load LiveKit SDK');
        };
        document.head.appendChild(script);
    } else if (window.LivekitClient) {
        console.log('LiveKit SDK already loaded');
        window.LiveKitSDK = window.LiveKitSDK || window.LivekitClient;
        window.livekitSDKLoaded = true;
    }

    // Add LiveKit CSS if not present
    if (!document.querySelector('link[href*="livekit-client.css"]')) {
        const css = document.createElement('link');
        css.rel = 'stylesheet';
        css.href = '/static/livekit-client.css';
        document.head.appendChild(css);
    }

    // Store server URL and token in window
    window.LIVEKIT_URL = '{{ server_url }}';
    window.LIVEKIT_TOKEN = '{{ user_token }}';
    window.ROOM_NAME = '{{ room_name }}';
    let audioUnlocked = false;
    const audioBanner = document.getElementById('audioPermissionBanner');
    const enableAudioBtn = document.getElementById('enableAudioBtn');
    const startVoiceBtn = document.getElementById('startVoiceBtn');
    const gestureHint = document.getElementById('gestureHint');
    const ua = navigator.userAgent || '';
    const isiPadOS = /iPad/.test(ua) || (ua.includes('Macintosh') && 'ontouchend' in document);
    const isMobileTouch = window.matchMedia('(pointer: coarse)').matches && /Mobile|Tablet|Android|iP(ad|hone|od)/i.test(ua);
    const requiresUserGesture = isiPadOS || isMobileTouch;
    let userGestureSatisfied = !requiresUserGesture;
    const showStartPrompt = () => {
        if (!requiresUserGesture) return;
        if (startVoiceBtn) {
            startVoiceBtn.classList.remove('hidden');
            startVoiceBtn.disabled = false;
            startVoiceBtn.textContent = 'Start Voice Session';
        }
        if (gestureHint) {
            gestureHint.classList.remove('hidden');
        }
    };
    const hideStartPrompt = () => {
        if (startVoiceBtn) {
            startVoiceBtn.classList.add('hidden');
        }
        if (gestureHint) {
            gestureHint.classList.add('hidden');
        }
    };
    let connectionMonitor = null;
    let monitorFailures = 0;
    let reconnectLock = false;
    let reconnectAttempts = 0;
    let manualDisconnect = false;

    if (requiresUserGesture) {
        showStartPrompt();
    }

    if (startVoiceBtn) {
        startVoiceBtn.addEventListener('click', async () => {
            userGestureSatisfied = true;
            manualDisconnect = false;
            hideStartPrompt();
            startVoiceBtn.disabled = true;
            startVoiceBtn.classList.add('opacity-70');
            startVoiceBtn.textContent = 'Starting...';
            try {
                await connectToRoom();
            } catch (err) {
                console.warn('Voice start failed after user gesture', err);
                showStartPrompt();
            } finally {
                startVoiceBtn.classList.remove('opacity-70');
            }
        });
    }

    // Update UI status
    function updateStatus(state, message) {
        const statusIndicator = document.getElementById('statusIndicator');
        const statusText = document.getElementById('statusText');
        
        if (!statusIndicator || !statusText) return;
        
        statusText.textContent = message;
        
        switch(state) {
            case 'connecting':
                statusIndicator.className = 'w-3 h-3 rounded-full bg-yellow-500 animate-pulse';
                break;
            case 'connected':
                statusIndicator.className = 'w-3 h-3 rounded-full bg-green-500';
                break;
            case 'error':
                statusIndicator.className = 'w-3 h-3 rounded-full bg-red-500';
                break;
            case 'disconnected':
                statusIndicator.className = 'w-3 h-3 rounded-full bg-gray-500';
                break;
        }
    }

    // Microphone control functions
    window.toggleMute = function() {
        if (!window.livekitRoom) return;
        
        const localParticipant = window.livekitRoom.localParticipant;
        const audioTracks = localParticipant.audioTracks;
        
        audioTracks.forEach(publication => {
            if (publication.track) {
                const newMuted = !publication.track.isMuted;
                publication.track.mute(newMuted);
                updateMuteButton(newMuted);
                console.log(newMuted ? 'ðŸ”‡ Microphone muted' : 'ðŸŽ¤ Microphone unmuted');
            }
        });
    };

    function updateMuteButton(isMuted) {
        const muteBtn = document.getElementById('muteBtn');
        if (!muteBtn) return;
        
        if (isMuted) {
            muteBtn.innerHTML = '<svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5.586 15L4.172 16.414A2 2 0 003 18.828V21a1 1 0 001 1h3.172a2 2 0 001.414-.586L15 15m2 2l5.586-5.586A2 2 0 0024 8.172V5a1 1 0 00-1-1h-3.172a2 2 0 00-1.414.586L13 10"></path></svg>';
            muteBtn.classList.add('bg-red-500', 'hover:bg-red-600');
            muteBtn.classList.remove('bg-dark-elevated', 'hover:bg-dark-border');
        } else {
            muteBtn.innerHTML = '<svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"></path></svg>';
            muteBtn.classList.remove('bg-red-500', 'hover:bg-red-600');
            muteBtn.classList.add('bg-dark-elevated', 'hover:bg-dark-border');
        }
    }

    function clearConnectionMonitor() {
        if (connectionMonitor) {
            clearInterval(connectionMonitor);
            connectionMonitor = null;
        }
    }

    function scheduleConnectionMonitor() {
        clearConnectionMonitor();
        connectionMonitor = setInterval(() => {
            if (!window.livekitRoom || manualDisconnect) {
                monitorFailures = 0;
                return;
            }

            const room = window.livekitRoom;
            const state = room.state;
            const participantsMap = room.participants || room.remoteParticipants || new Map();
            const participants = Array.from(participantsMap.values());
            const agentPresent = participants.some(p => (p.identity || '').includes('agent'));

            const connectionIssue = state !== 'connected';
            const agentMissing = !agentPresent;

            if (connectionIssue || agentMissing) {
                monitorFailures += 1;
                console.warn('LiveKit monitor detected degraded state', { state, agentPresent, monitorFailures });
            } else {
                monitorFailures = 0;
            }

            if (connectionIssue && monitorFailures >= 3) {
                monitorFailures = 0;
                reconnectToRoom('connection-monitor');
            }
        }, 8000);
    }

    async function reconnectToRoom(reason = 'unknown') {
        if (manualDisconnect) {
            console.log('Reconnect skipped due to manual disconnect.');
            return;
        }
        if (reconnectLock) {
            console.log('Reconnect already in progress; skipping parallel attempt.');
            return;
        }
        reconnectLock = true;
        reconnectAttempts += 1;
        if (reconnectAttempts > 5) {
            console.error('Max LiveKit reconnect attempts reached. Giving up until manual retry.');
            reconnectLock = false;
            return;
        }
        console.log(`ðŸ”„ Reconnecting to LiveKit (${reason}) - attempt ${reconnectAttempts}`);
        try {
            if (window.livekitRoom && window.livekitRoom.state !== 'disconnected') {
                try {
                    await window.livekitRoom.disconnect();
                } catch (disconnectErr) {
                    console.warn('Error disconnecting prior to reconnect:', disconnectErr);
                }
            }
            await new Promise(resolve => setTimeout(resolve, 600));
            if (requiresUserGesture && !userGestureSatisfied) {
                console.log('Reconnect awaiting fresh user gesture.');
                updateStatus('disconnected', 'Tap Start Voice to reconnect');
                showStartPrompt();
            } else {
                connectToRoom(true);
            }
        } finally {
            reconnectLock = false;
        }
    }

    window.disconnectVoice = function() {
        manualDisconnect = true;
        clearConnectionMonitor();
        // Keep the LiveKit room connected so audio can finish streaming.
        updateStatus('disconnected', 'Disconnected');
        stopTranscriptStream();
        if (requiresUserGesture) {
            showStartPrompt();
        }
    };

    // Main connect function
    window.connectToRoom = async function(isReconnect = false) {
        console.log('ðŸš€ Starting LiveKit connection...');
        if (requiresUserGesture && !userGestureSatisfied) {
            console.warn('Voice connection blocked: awaiting user gesture');
            showStartPrompt();
            return;
        }
        hideStartPrompt();
        updateStatus('connecting', isReconnect ? 'Reconnecting to voice room...' : 'Connecting to voice room...');
        manualDisconnect = false;

        // Wait for SDK to load
        let attempts = 0;
        while (!window.livekitSDKLoaded && attempts < 50) {
            await new Promise(resolve => setTimeout(resolve, 100));
            attempts++;
        }
        
        if (!window.livekitSDKLoaded || !window.LiveKitSDK) {
            console.error('LiveKit SDK not loaded after 5 seconds');
            updateStatus('error', 'Failed to load voice components');
            return;
        }
        
        const LiveKit = window.LiveKitSDK;
        
        try {
            const room = new LiveKit.Room({
                adaptiveStream: true,
                dynacast: true,
                videoCaptureDefaults: {
                    resolution: { width: 1280, height: 720 },
                    frameRate: 30,
                },
                audioCaptureDefaults: {
                    autoGainControl: true,
                    echoCancellation: true,
                    noiseSuppression: true,
                    sampleRate: 48000,
                    channelCount: 1,
                },
                publishDefaults: {
                    audioPreset: LiveKit.AudioPresets.speech,
                    simulcast: false,
                    stopMicTrackOnMute: false,
                },
            });
            
            window.livekitRoom = room;
            
            // Event handlers
            room.on(LiveKit.RoomEvent.Connected, () => {
                console.log('âœ… Connected to room:', room.name);
                updateStatus('connected', 'Connected to voice room');
                hideStartPrompt();
                document.getElementById('muteBtn').disabled = false;
                
                // Start transcript streaming when connected
                startTranscriptStream();
                scheduleConnectionMonitor();
                reconnectAttempts = 0;
            });

            room.on(LiveKit.RoomEvent.Disconnected, (reason) => {
                console.log('ðŸ”Œ Disconnected from room:', reason);
                updateStatus('disconnected', 'Disconnected from voice room');
                document.getElementById('muteBtn').disabled = true;
                
                // Stop transcript streaming when disconnected
                stopTranscriptStream();
                clearConnectionMonitor();
                if (manualDisconnect && requiresUserGesture) {
                    showStartPrompt();
                }
                if (!manualDisconnect) {
                    setTimeout(() => reconnectToRoom('event-disconnected'), 1200);
                }
            });

            room.on(LiveKit.RoomEvent.ParticipantConnected, (participant) => {
                console.log('ðŸ‘¤ Participant connected:', participant.identity);
                if (participant.identity.includes('agent')) {
                    document.getElementById('agentStatus').classList.remove('hidden');
                }
            });

            room.on(LiveKit.RoomEvent.ParticipantDisconnected, (participant) => {
                console.log('ðŸ‘¤ Participant disconnected:', participant.identity);
                if (participant.identity.includes('agent')) {
                    document.getElementById('agentStatus').classList.add('hidden');
                    if (!manualDisconnect) {
                        setTimeout(() => reconnectToRoom('agent-left'), 1000);
                    }
                }
            });
            
            room.on(LiveKit.RoomEvent.TrackSubscribed, (track, publication, participant) => {
                console.log('ðŸŽµ Track subscribed:', track.kind, 'from', participant.identity);
                
                if (track.kind === 'audio') {
                    try {
                        track.setEnabled?.(true);
                        track.setVolume?.(1.0);
                    } catch {}

                    let audioElement = window.__admin_lk_audio_el;
                    if (!audioElement || !document.body.contains(audioElement)) {
                        audioElement = document.createElement('audio');
                        audioElement.autoplay = true;
                        audioElement.playsInline = true;
                        audioElement.muted = false;
                        try { audioElement.volume = 1.0; } catch {}
                        audioElement.style.position = 'fixed';
                        audioElement.style.bottom = '8px';
                        audioElement.style.right = '8px';
                        audioElement.style.width = '0px';
                        audioElement.style.height = '0px';
                        audioElement.style.opacity = '0';
                        audioElement.style.pointerEvents = 'none';
                        document.body.appendChild(audioElement);
                        window.__admin_lk_audio_el = audioElement;
                    }

                    try {
                        const previous = track.detach?.() || [];
                        previous.forEach((node) => { try { node.remove?.(); } catch {} });
                    } catch {}

                    try { track.attach(audioElement); } catch {}

                    try {
                        if (track.mediaStreamTrack) {
                            const ms = new MediaStream();
                            ms.addTrack(track.mediaStreamTrack);
                            audioElement.srcObject = ms;
                        }
                    } catch {}

                    const attemptPlay = async () => {
                        try { await startAudioPlayback(true); } catch {}
                        try {
                            const playPromise = audioElement.play?.();
                            if (playPromise && typeof playPromise.catch === 'function') {
                                await playPromise.catch((err) => {
                                    console.warn('ðŸ”‡ Audio playback blocked:', err);
                                    if (audioBanner) audioBanner.classList.remove('hidden');
                                });
                            } else {
                                audioUnlocked = true;
                                if (audioBanner) audioBanner.classList.add('hidden');
                            }
                        } catch (err) {
                            console.warn('ðŸ”‡ Audio playback failed:', err);
                            if (audioBanner) audioBanner.classList.remove('hidden');
                        }
                    };
                    attemptPlay();

                    if (enableAudioBtn && !enableAudioBtn.dataset.bound) {
                        enableAudioBtn.dataset.bound = 'true';
                        enableAudioBtn.addEventListener('click', attemptPlay);
                    }

                    console.log('ðŸ”Š Audio track attached and playing');
                }
            });
            
            room.on(LiveKit.RoomEvent.TrackUnsubscribed, (track) => {
                console.log('ðŸ”‡ Track unsubscribed:', track.kind);
                try {
                    const nodes = track.detach?.() || [];
                    nodes.forEach((node) => { try { node.remove?.(); } catch {} });
                } catch {}
                try {
                    if (track?.kind === 'audio' && window.__admin_lk_audio_el) {
                        window.__admin_lk_audio_el.srcObject = null;
                    }
                } catch {}
            });
            
            room.on(LiveKit.RoomEvent.LocalTrackPublished, (publication) => {
                console.log('ðŸ“¤ Local track published:', publication.trackName);
                document.getElementById('micStatus').textContent = 'Microphone: Active';
                document.getElementById('audioLevelContainer').classList.remove('hidden');
            });
            
            room.on(LiveKit.RoomEvent.LocalTrackUnpublished, (publication) => {
                console.log('ðŸ“¤ Local track unpublished:', publication.trackName);
                document.getElementById('micStatus').textContent = 'Microphone: Inactive';
                document.getElementById('audioLevelContainer').classList.add('hidden');
            });
            
            room.on(LiveKit.RoomEvent.AudioPlaybackStatusChanged, () => {
                if (room.canPlaybackAudio) {
                    console.log('ðŸ”Š Audio playback enabled');
                } else {
                    console.log('ðŸ”‡ Audio playback disabled - user interaction may be required');
                }
            });
            
            room.on(LiveKit.RoomEvent.MediaDevicesError, (error) => {
                console.error('ðŸŽ¤ Media device error:', error);
                updateStatus('error', 'Microphone access denied or unavailable');
                document.getElementById('micStatus').textContent = 'Microphone: Error';
                showStartPrompt();
            });
            
            room.on(LiveKit.RoomEvent.ConnectionQualityChanged, (quality, participant) => {
                if (participant === room.localParticipant) {
                    console.log('ðŸ“¶ Connection quality:', quality);
                }
            });
            
            // Audio level monitoring for local participant
            room.on(LiveKit.RoomEvent.LocalAudioLevelChanged, (level) => {
                const audioLevel = document.getElementById('audioLevel');
                if (audioLevel) {
                    const percentage = Math.min(100, level * 100);
                    audioLevel.style.width = percentage + '%';
                }
            });
            
            // Connect to room
            console.log('ðŸ”— Connecting to LiveKit URL:', window.LIVEKIT_URL);
            console.log('ðŸŽ« Using token for room:', window.ROOM_NAME);
            
            await room.connect(window.LIVEKIT_URL, window.LIVEKIT_TOKEN);
            
            // Publish microphone
            try {
                await room.localParticipant.setMicrophoneEnabled(true);
                console.log('ðŸŽ¤ Microphone enabled and publishing');
            } catch (e) {
                console.error('Failed to enable microphone:', e);
                document.getElementById('micStatus').textContent = 'Microphone: Failed to enable';
            }
            
            try {
                await startAudioPlayback();
            } catch (e) {
                console.log('Audio playback requires user interaction.');
            }

        } catch (error) {
            console.error('âŒ Failed to connect:', error);
            updateStatus('error', 'Failed to connect to voice room');
            clearConnectionMonitor();
            if (requiresUserGesture) {
                showStartPrompt();
            }
            if (!manualDisconnect) {
                setTimeout(() => reconnectToRoom('connect-error'), 2000);
            }
        }
    };

    async function startAudioPlayback(manual = false) {
        if (!window.livekitRoom) return;
        try {
            await window.livekitRoom.startAudio();
            audioUnlocked = true;
            if (audioBanner) audioBanner.classList.add('hidden');
            console.log(manual ? 'ðŸ”Š Audio playback enabled by user' : 'ðŸ”Š Audio playback started');
        } catch (e) {
            console.log('âš ï¸ Could not start audio playback', e);
            if (audioBanner) audioBanner.classList.remove('hidden');
            throw e;
        }
    }

    // Auto-connect on load
    if (window.LIVEKIT_URL && window.LIVEKIT_TOKEN) {
        if (requiresUserGesture) {
            console.log('ðŸ“± Awaiting user gesture before connecting to LiveKit');
            updateStatus('disconnected', 'Tap Start Voice to connect');
            showStartPrompt();
        } else {
            console.log('ðŸŽ¬ Auto-connecting to room...');
            setTimeout(() => {
                connectToRoom();
            }, 500);
        }
    } else {
        console.error('Missing LiveKit configuration');
        updateStatus('error', 'Missing voice configuration');
    }

    document.addEventListener('visibilitychange', () => {
        if (!document.hidden && window.livekitRoom && window.livekitRoom.state === 'connected') {
            startAudioPlayback(true).catch(err => console.warn('Failed to resume audio on visibility change', err));
        }
    });

    window.addEventListener('focus', () => {
        if (window.livekitRoom && window.livekitRoom.state === 'connected') {
            startAudioPlayback(true).catch(err => console.warn('Failed to resume audio on window focus', err));
        }
    });
})();

// Handle cleanup when leaving page
window.addEventListener('beforeunload', function() {
    if (window.livekitRoom && window.livekitRoom.state === 'connected') {
        console.log('ðŸ§¹ Page unload - disconnecting from LiveKit...');
        try {
            window.livekitRoom.disconnect();
        } catch (e) {
            console.warn('Error during cleanup:', e);
        }
    }
    // Stop transcript streaming
    stopTranscriptStream();
});

// Also handle page visibility changes
document.addEventListener('visibilitychange', function() {
    // Log but don't disconnect when tab becomes hidden
    if (document.hidden && window.livekitRoom && window.livekitRoom.state === 'connected') {
        console.log('ðŸ“± Tab hidden but keeping LiveKit connection alive');
    }
});

// Handle HTMX navigation away from this page
// Keep the LiveKit connection active during HTMX swaps; transcripts can reconnect separately.
document.body.addEventListener('htmx:beforeSwap', function(evt) {
    stopTranscriptStream();
});

// Start transcript stream immediately if we have the conversation ID
if ('{{ conversation_id }}') {
    console.log('Starting transcript stream for conversation: {{ conversation_id }}');
    // Wait a bit for the page to be fully loaded
    setTimeout(startTranscriptStream, 1000);
}
</script>
