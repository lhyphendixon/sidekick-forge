<!-- Live Voice Chat Interface with LiveKit Client -->
<div id="voiceStatus">
<div class="h-96 flex flex-col p-4">
    <!-- Status Header -->
    <div class="text-center mb-4">
        <div id="connectionStatus" class="flex items-center justify-center gap-2 mb-2">
            <div class="w-3 h-3 rounded-full bg-yellow-500 animate-pulse" id="statusIndicator"></div>
            <span class="text-sm text-dark-text-secondary" id="statusText">Connecting to voice room...</span>
        </div>
        <p class="text-xs text-dark-text-secondary">Room: {{ room_name }}</p>
        <p class="text-xs text-dark-text-secondary" id="participantCount">0 participants</p>
    </div>
    
    <!-- Audio Visualization -->
    <div class="flex-1 flex items-center justify-center">
        <div id="audioContainer" class="text-center">
            <!-- Microphone Status -->
            <div class="mb-6">
                <div id="micIcon" class="w-20 h-20 mx-auto mb-2 text-dark-text-secondary">
                    <svg fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"></path>
                    </svg>
                </div>
                <p class="text-sm text-dark-text" id="micStatus">Microphone: Checking...</p>
            </div>
            
            <!-- Audio Level Indicator -->
            <div class="max-w-xs mx-auto mb-4 hidden" id="audioLevelContainer">
                <div class="h-2 bg-dark-elevated rounded-full overflow-hidden">
                    <div id="audioLevel" class="h-full bg-brand-teal transition-all duration-100 ease-out" style="width: 0%"></div>
                </div>
                <p class="text-xs text-dark-text-secondary mt-1">Audio Level</p>
            </div>
            
            <!-- Agent Status -->
            <div id="agentStatus" class="hidden">
                <p class="text-sm text-brand-teal mb-2">Agent Connected</p>
                <p class="text-xs text-dark-text-secondary">Listening for "{{ agent_slug }}"</p>
            </div>
        </div>
    </div>
    
    <!-- Controls -->
    <div class="border-t border-dark-border pt-4">
        <div class="flex justify-center gap-3">
            <!-- Mute Button -->
            <button id="muteBtn" 
                    onclick="window.voicePreview.toggleMute()"
                    class="p-3 rounded-full bg-dark-elevated text-dark-text hover:bg-dark-border transition-all disabled:opacity-50"
                    disabled>
                <svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"></path>
                </svg>
            </button>
            
            <!-- Disconnect Button -->
            <button id="disconnectBtn"
                    hx-post="/admin/agents/preview/{{ client_id }}/{{ agent_slug }}/voice-stop"
                    hx-vals='{"session_id": "{{ session_id }}", "room_name": "{{ room_name }}"}'
                    hx-target="#voiceStatus"
                    hx-swap="innerHTML"
                    hx-on::before-request="window.voicePreview.disconnect()"
                    hx-on::response-error="console.warn('Voice stop error:', event.detail)"
                    class="px-4 py-2 bg-brand-salmon text-white rounded-lg hover:bg-brand-salmon/90 transition-all flex items-center gap-2">
                <svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"></path>
                </svg>
                Disconnect
            </button>
        </div>
    </div>
</div>
</div>

<script>
(function() {
    'use strict';
    
    // Create a namespace for voice preview to avoid global pollution
    const voicePreview = window.voicePreview || {};
    
    // State variables
    let room = null;
    let localParticipant = null;
    let audioTrack = null;
    let isMuted = false;
    
    // Initialize LiveKit connection
    voicePreview.initialize = async function() {
        try {
            // Check if LiveKit client is loaded
            let LiveKitSDK = window.LiveKitSDK || window.LiveKit || window.livekit || window.LivekitClient;
            
            if (!LiveKitSDK) {
                console.error('LiveKit client SDK not found');
                updateStatus('error', 'LiveKit SDK not loaded');
                return;
            }
            
            console.log('LiveKit client SDK loaded successfully as:', LiveKitSDK);
            
            // Debug: Log connection details
            console.log('LiveKit Connection Details:');
            console.log('Server URL:', '{{ server_url }}');
            console.log('User Token length:', '{{ user_token }}'.length);
            console.log('User Token:', '{{ user_token }}'.substring(0, 50) + '...');
            console.log('Room Name:', '{{ room_name }}');
            
            // Update status
            updateStatus('connecting', 'Requesting microphone permissions...');
            
            // Request microphone permission
            try {
                await navigator.mediaDevices.getUserMedia({ audio: true });
                console.log('âœ… Microphone permission granted');
                updateStatus('connecting', 'Connecting to voice room...');
            } catch (permError) {
                console.error('âŒ Microphone permission denied:', permError);
                updateStatus('error', 'Microphone permission required');
                return;
            }
            
            // Create room instance
            room = new LiveKitSDK.Room({
                adaptiveStream: true,
                dynacast: true,
                logLevel: 'warn'
            });
            
            // Set up event handlers
            room.on('connected', handleConnected);
            room.on('disconnected', handleDisconnected);
            room.on('participantConnected', handleParticipantConnected);
            room.on('participantDisconnected', handleParticipantDisconnected);
            room.on('trackSubscribed', handleTrackSubscribed);
            room.on('localTrackPublished', handleLocalTrackPublished);
            room.on('connectionStateChanged', handleConnectionStateChanged);
            room.on('reconnecting', () => updateStatus('reconnecting', 'Reconnecting...'));
            room.on('reconnected', () => updateStatus('connected', 'Reconnected'));
            
            // Connect to room
            console.log('Attempting to connect to room...');
            console.log('Using LiveKit client version:', LiveKitSDK.version || 'Unknown');
            
            const startTime = Date.now();
            await room.connect('{{ server_url }}', '{{ user_token }}');
            const connectTime = Date.now() - startTime;
            console.log(`âœ… Connection successful in ${connectTime}ms`);
            
        } catch (error) {
            console.error('âŒ Failed to connect:', error);
            updateStatus('error', `Connection failed: ${error.message}`);
        }
    };
    
    // Event handlers
    function handleConnected() {
        console.log('Connected to LiveKit room');
        localParticipant = room.localParticipant;
        updateStatus('connected', 'Connected - Agent dispatched in parallel, should join shortly...');
        
        // Enable microphone
        enableMicrophone();
        
        // Agent dispatch happens in parallel on backend for minimal latency
        // No need to dispatch from frontend anymore
    }
    
    function handleDisconnected() {
        console.log('Disconnected from LiveKit room');
        updateStatus('disconnected', 'Disconnected from voice room');
        localParticipant = null;
        audioTrack = null;
    }
    
    function handleParticipantConnected(participant) {
        console.log('Participant connected:', participant.identity);
        updateParticipantList();
        
        if (participant.identity.startsWith('agent-')) {
            updateStatus('agent-ready', 'Agent ready - Say hello!');
            const agentStatus = document.getElementById('agentStatus');
            if (agentStatus) {
                agentStatus.classList.remove('hidden');
            }
            
            // Show notification that agent has joined
            showNotification('Agent has joined the conversation', 'success');
        }
    }
    
    function updateParticipantList() {
        if (!room) return;
        
        try {
            // Handle different types of room.participants
            let participantArray = [];
            if (room.participants && typeof room.participants.values === 'function') {
                // It's a Map or similar
                participantArray = Array.from(room.participants.values());
            } else if (room.participants && Array.isArray(room.participants)) {
                // It's already an array
                participantArray = room.participants;
            } else if (room.participants && typeof room.participants === 'object') {
                // It's a plain object, get values
                participantArray = Object.values(room.participants);
            }
            
            const participants = [room.localParticipant, ...participantArray].filter(p => p);
            const participantCount = participants.length;
            const agentPresent = participants.some(p => p && p.identity && p.identity.startsWith('agent-'));
            
            // Update participant count in UI
            const countElement = document.getElementById('participantCount');
            if (countElement) {
                countElement.textContent = `${participantCount} participant${participantCount !== 1 ? 's' : ''}`;
            }
            
            // Log participant details
            console.log(`Participants (${participantCount}):`, participants.map(p => p?.identity || 'unknown'));
        } catch (error) {
            console.error('Error updating participant list:', error);
            console.log('room.participants type:', typeof room.participants);
            console.log('room.participants:', room.participants);
        }
    }
    
    function showNotification(message, type = 'info') {
        // Create notification element
        const notification = document.createElement('div');
        notification.className = `fixed top-4 right-4 px-4 py-2 rounded-lg text-white z-50 transition-opacity duration-300 ${
            type === 'success' ? 'bg-green-500' : 
            type === 'error' ? 'bg-red-500' : 
            'bg-blue-500'
        }`;
        notification.textContent = message;
        document.body.appendChild(notification);
        
        // Remove after 3 seconds
        setTimeout(() => {
            notification.style.opacity = '0';
            setTimeout(() => notification.remove(), 300);
        }, 3000);
    }
    
    function handleTrackSubscribed(track, publication, participant) {
        console.log(`ðŸŽ§ Track subscribed: ${track.kind} from ${participant.identity}`);
        
        if (track.kind === 'audio' && participant.identity.startsWith('agent-')) {
            console.log('ðŸ”Š Agent audio track subscribed - attaching to audio element');
            
            // Create or get audio element
            let audioElement = document.getElementById('agentAudio');
            if (!audioElement) {
                audioElement = document.createElement('audio');
                audioElement.id = 'agentAudio';
                audioElement.autoplay = true;
                document.body.appendChild(audioElement);
            }
            
            // Attach track to audio element
            track.attach(audioElement);
            console.log('âœ… Agent audio track attached for playback');
        }
    }
    
    function handleLocalTrackPublished(publication) {
        if (publication.kind === 'audio') {
            audioTrack = publication.track;
            console.log('Audio track published');
            showNotification('Microphone connected', 'success');
        }
    }
    
    function handleParticipantDisconnected(participant) {
        console.log('Participant disconnected:', participant.identity);
        updateParticipantList();
        
        if (participant.identity.startsWith('agent-')) {
            updateStatus('connected', 'Agent disconnected - Waiting for new agent...');
            const agentStatus = document.getElementById('agentStatus');
            if (agentStatus) {
                agentStatus.classList.add('hidden');
            }
            showNotification('Agent has left the conversation', 'info');
        }
    }
    
    function handleConnectionStateChanged(state) {
        console.log('Connection state changed:', state);
        
        switch(state) {
            case 'connected':
                updateStatus('connected', 'Connected - Waiting for agent...');
                break;
            case 'disconnected':
                updateStatus('disconnected', 'Disconnected');
                break;
            case 'reconnecting':
                updateStatus('reconnecting', 'Connection lost - Reconnecting...');
                showNotification('Connection lost, attempting to reconnect...', 'error');
                break;
        }
    }
    
    // Enable microphone
    async function enableMicrophone() {
        try {
            await room.localParticipant.setMicrophoneEnabled(true);
            document.getElementById('muteBtn').disabled = false;
            updateMicStatus('Microphone: Active');
            
            // Show audio level indicator
            document.getElementById('audioLevelContainer').classList.remove('hidden');
            
        } catch (error) {
            console.error('Failed to enable microphone:', error);
            updateMicStatus('Microphone: Error');
        }
    }
    
    // Toggle mute
    voicePreview.toggleMute = function() {
        if (!room || !room.localParticipant) return;
        
        isMuted = !isMuted;
        room.localParticipant.setMicrophoneEnabled(!isMuted);
        
        const muteBtn = document.getElementById('muteBtn');
        const micIcon = muteBtn.querySelector('svg');
        
        if (isMuted) {
            muteBtn.classList.add('bg-brand-salmon');
            muteBtn.classList.remove('bg-dark-elevated');
            updateMicStatus('Microphone: Muted');
            // Update icon to muted
            micIcon.innerHTML = '<path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5.586 15L3.172 12.586a1 1 0 010-1.414l.707-.707a1 1 0 011.414 0L7.707 13m0 0L10.121 10.586a1 1 0 011.414 0l.707.707a1 1 0 010 1.414L9.828 15m-2.121-2L5.586 15m2.121-2L9.828 15"></path>';
        } else {
            muteBtn.classList.remove('bg-brand-salmon');
            muteBtn.classList.add('bg-dark-elevated');
            updateMicStatus('Microphone: Active');
            // Update icon to unmuted
            micIcon.innerHTML = '<path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"></path>';
        }
    };
    
    // Dispatch agent to the room
    async function dispatchAgent() {
        try {
            console.log('Dispatching agent to room {{ room_name }}...');
            
            const response = await fetch('/api/v1/agents/dispatch-to-room', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({
                    room_name: '{{ room_name }}',
                    agent_name: '{{ agent_slug }}'
                })
            });
            
            const data = await response.json();
            
            if (response.ok && data.success) {
                console.log('âœ… Agent dispatch successful:', data);
            } else {
                console.error('âŒ Agent dispatch failed:', data);
                updateStatus('error', `Failed to dispatch agent: ${data.detail || 'Unknown error'}`);
            }
        } catch (error) {
            console.error('âŒ Error dispatching agent:', error);
            updateStatus('error', 'Failed to dispatch agent');
        }
    }
    
    // Disconnect from voice
    voicePreview.disconnect = async function() {
        if (room) {
            try {
                // Only disconnect if we're actually connected
                if (room.state === 'connected') {
                    await room.disconnect();
                }
            } catch (error) {
                console.warn('Error during disconnect:', error);
            } finally {
                // Clean up references regardless
                room = null;
                localParticipant = null;
                audioTrack = null;
                isMuted = false;
            }
        }
    };
    
    // Update functions
    function updateStatus(state, text) {
        const indicator = document.getElementById('statusIndicator');
        const statusText = document.getElementById('statusText');
        
        statusText.textContent = text;
        
        // Update indicator color based on state
        indicator.className = 'w-3 h-3 rounded-full ';
        switch(state) {
            case 'connecting':
                indicator.className += 'bg-yellow-500 animate-pulse';
                break;
            case 'connected':
                indicator.className += 'bg-yellow-500 animate-pulse';  // Still yellow - waiting for agent
                break;
            case 'agent-ready':
                indicator.className += 'bg-green-500';  // Green when agent is ready
                break;
            case 'error':
                indicator.className += 'bg-red-500';
                break;
            case 'disconnected':
                indicator.className += 'bg-gray-500';
                break;
        }
    }
    
    function updateMicStatus(text) {
        document.getElementById('micStatus').textContent = text;
    }
    
    // Audio level monitoring
    if (typeof window.requestAnimationFrame !== 'undefined') {
        let animationFrameId;
        
        function monitorAudioLevel() {
            if (room && room.localParticipant && audioTrack) {
                // This is a simplified version - LiveKit may provide audio level APIs
                const level = Math.random() * 100; // Placeholder - use actual audio level
                document.getElementById('audioLevel').style.width = level + '%';
            }
            animationFrameId = requestAnimationFrame(monitorAudioLevel);
        }
        
        // Start monitoring when connected
        room && room.on('connected', () => {
            monitorAudioLevel();
        });
        
        // Stop monitoring when disconnected
        room && room.on('disconnected', () => {
            if (animationFrameId) {
                cancelAnimationFrame(animationFrameId);
            }
        });
    }
    
    // Make voicePreview available globally
    window.voicePreview = voicePreview;
    
    // Initialize when ready
    if (document.readyState === 'complete' || document.readyState === 'interactive') {
        setTimeout(() => voicePreview.initialize(), 500);
    } else {
        document.addEventListener('DOMContentLoaded', () => {
            setTimeout(() => voicePreview.initialize(), 500);
        });
    }
    
})();
</script>