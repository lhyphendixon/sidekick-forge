<!-- Live Voice Chat Interface with LiveKit Client -->
<div class="h-96 flex flex-col p-4">
    <!-- Status Header -->
    <div class="text-center mb-4">
        <div id="connectionStatus" class="flex items-center justify-center gap-2 mb-2">
            <div class="w-3 h-3 rounded-full bg-yellow-500 animate-pulse" id="statusIndicator"></div>
            <span class="text-sm text-dark-text-secondary" id="statusText">Connecting to voice room...</span>
        </div>
        <p class="text-xs text-dark-text-secondary">Room: {{ room_name }}</p>
    </div>
    
    <!-- Audio Visualization -->
    <div class="flex-1 flex items-center justify-center">
        <div id="audioContainer" class="text-center">
            <!-- Microphone Status -->
            <div class="mb-6">
                <div id="micIcon" class="w-20 h-20 mx-auto mb-2 text-dark-text-secondary">
                    <svg fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"></path>
                    </svg>
                </div>
                <p class="text-sm text-dark-text" id="micStatus">Microphone: Checking...</p>
            </div>
            
            <!-- Audio Level Indicator -->
            <div class="max-w-xs mx-auto mb-4 hidden" id="audioLevelContainer">
                <div class="h-2 bg-dark-elevated rounded-full overflow-hidden">
                    <div id="audioLevel" class="h-full bg-brand-teal transition-all duration-100 ease-out" style="width: 0%"></div>
                </div>
                <p class="text-xs text-dark-text-secondary mt-1">Audio Level</p>
            </div>
            
            <!-- Agent Status -->
            <div id="agentStatus" class="hidden">
                <p class="text-sm text-brand-teal mb-2">Agent Connected</p>
                <p class="text-xs text-dark-text-secondary">Listening for "{{ agent_slug or (agent.slug if agent else 'agent') }}"</p>
            </div>
        </div>
    </div>
    
    <!-- Controls -->
    <div class="border-t border-dark-border pt-4">
        <div class="flex justify-center gap-3">
            <!-- Mute Button -->
            <button id="muteBtn" 
                    onclick="toggleMute()"
                    class="p-3 rounded-full bg-dark-elevated text-dark-text hover:bg-dark-border transition-all disabled:opacity-50"
                    disabled>
                <svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"></path>
                </svg>
            </button>
            
            <!-- Disconnect Button -->
            <button id="disconnectBtn"
                    hx-post="/admin/agents/preview/{{ client_id }}/{{ agent_slug }}/voice-stop"
                    hx-vals='{"session_id": "{{ session_id }}", "room_name": "{{ room_name }}"}'
                    hx-target="#voiceStatus"
                    hx-swap="innerHTML"
                    onclick="disconnectVoice()"
                    class="px-4 py-2 bg-brand-salmon text-white rounded-lg hover:bg-brand-salmon/90 transition-all flex items-center gap-2">
                <svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"></path>
                </svg>
                Disconnect
            </button>
        </div>
    </div>
</div>

<script>
// Wrap entire script in IIFE to avoid global conflicts
(function() {
    // Ensure LiveKit SDK is loaded
    if (!window.LivekitClient && !document.querySelector('script[src*="livekit-client"]')) {
        const script = document.createElement('script');
        script.src = '/static/livekit-client.min.js';
        script.onload = () => {
            console.log('LiveKit SDK loaded dynamically');
            window.LiveKitSDK = window.LivekitClient;
            window.livekitSDKLoaded = true;
        };
        script.onerror = () => {
            console.error('Failed to load LiveKit SDK');
            window.livekitSDKLoaded = false;
            updateStatus('error', 'Failed to load LiveKit SDK');
        };
        document.head.appendChild(script);
    } else if (window.LivekitClient) {
        window.LiveKitSDK = window.LivekitClient;
        window.livekitSDKLoaded = true;
    }

    // LiveKit connection variables - use local scope within IIFE
    let room = null;
    let localParticipant = null;
    let audioTrack = null;
    let isMuted = false;
    let audioContext = null;
    let analyser = null;
    let microphone = null;

// Wait for LiveKit SDK to be available
async function waitForLiveKitSDK() {
    let attempts = 0;
    const maxAttempts = 20; // 10 seconds max wait
    
    while (attempts < maxAttempts) {
        // Check various possible SDK locations
        if (window.LiveKitSDK || window.LivekitClient || window.LiveKit || window.livekit || 
            typeof LivekitClient !== 'undefined' || typeof LiveKit !== 'undefined' || typeof livekit !== 'undefined') {
            console.log('LiveKit SDK found after', attempts * 500, 'ms');
            return true;
        }
        
        attempts++;
        await new Promise(resolve => setTimeout(resolve, 500));
    }
    
    console.error('LiveKit SDK not found after', maxAttempts * 500, 'ms');
    return false;
}

// Set up Web Audio API analyzer for raw audio monitoring
function setupAudioAnalyzer(mediaStreamTrack) {
    try {
        console.log('üéõÔ∏è Setting up Web Audio API analyzer...');
        
        // Create audio context if not exists
        if (!audioContext) {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
        }
        
        // Create media stream from track
        const stream = new MediaStream([mediaStreamTrack]);
        
        // Connect to audio context
        microphone = audioContext.createMediaStreamSource(stream);
        analyser = audioContext.createAnalyser();
        analyser.fftSize = 256;
        
        microphone.connect(analyser);
        
        // Create buffer for frequency data
        const bufferLength = analyser.frequencyBinCount;
        const dataArray = new Uint8Array(bufferLength);
        
        // Monitor audio levels
        let lastLogTime = 0;
        function checkAudioLevel() {
            analyser.getByteFrequencyData(dataArray);
            
            // Calculate average level
            let sum = 0;
            for (let i = 0; i < bufferLength; i++) {
                sum += dataArray[i];
            }
            const average = sum / bufferLength;
            
            // Log every 500ms if there's audio
            const now = Date.now();
            if (now - lastLogTime > 500 && average > 0) {
                console.log(`üéõÔ∏è Raw audio level (Web Audio API): ${average.toFixed(2)}/255 ${average > 5 ? 'üü¢ AUDIO DETECTED' : 'üü° VERY LOW'}`);
                lastLogTime = now;
            }
            
            // Continue monitoring
            requestAnimationFrame(checkAudioLevel);
        }
        
        checkAudioLevel();
        console.log('‚úÖ Web Audio API analyzer set up successfully');
        
    } catch (error) {
        console.error('Failed to set up audio analyzer:', error);
    }
}

// Initialize LiveKit connection
async function initializeLiveKit() {
    try {
        // Wait for SDK to be available
        const sdkAvailable = await waitForLiveKitSDK();
        if (!sdkAvailable) {
            console.error('LiveKit client SDK not loaded after waiting');
            updateStatus('error', 'LiveKit client SDK not loaded');
            return;
        }
        
        // Check if LiveKit client is loaded - use the consistent global variable
        let LiveKitSDK;
        if (window.LiveKitSDK) {
            LiveKitSDK = window.LiveKitSDK;
        } else if (typeof LivekitClient !== 'undefined') {
            LiveKitSDK = LivekitClient;
        } else if (typeof LiveKit !== 'undefined') {
            LiveKitSDK = LiveKit;
        } else if (typeof livekit !== 'undefined') {
            LiveKitSDK = livekit;
        } else if (window.LivekitClient) {
            LiveKitSDK = window.LivekitClient;
        } else if (window.LiveKit) {
            LiveKitSDK = window.LiveKit;
        } else if (window.livekit) {
            LiveKitSDK = window.livekit;
        } else {
            console.error('LiveKit client SDK not loaded - tried LiveKitSDK, LivekitClient, LiveKit, livekit');
            updateStatus('error', 'LiveKit client SDK not loaded');
            return;
        }
        console.log('LiveKit client SDK loaded successfully as:', LiveKitSDK);
        
        // Debug: Log connection details
        console.log('LiveKit Connection Details:');
        console.log('Server URL:', '{{ server_url }}');
        console.log('User Token length:', '{{ user_token }}'.length);
        console.log('User Token:', '{{ user_token }}'.substring(0, 50) + '...');
        console.log('Room Name:', '{{ room_name }}');
        console.log('Template variables check:');
        console.log('- server_url empty?', '{{ server_url }}' === '');
        console.log('- user_token empty?', '{{ user_token }}' === '');
        console.log('- room_name empty?', '{{ room_name }}' === '');
        
        // Extra debugging - log actual values
        const debugInfo = {
            server_url: '{{ server_url }}',
            user_token: '{{ user_token }}',
            room_name: '{{ room_name }}',
            hasServerUrl: Boolean('{{ server_url }}'),
            hasUserToken: Boolean('{{ user_token }}'),
            hasRoomName: Boolean('{{ room_name }}')
        };
        console.log('Debug info:', debugInfo);
        
        // Validate required variables
        if (!debugInfo.server_url || !debugInfo.user_token || !debugInfo.room_name) {
            console.error('Missing required template variables');
            console.error('Received values:', {
                server_url: debugInfo.server_url || 'MISSING',
                user_token: debugInfo.user_token ? 'Present' : 'MISSING',
                room_name: debugInfo.room_name || 'MISSING'
            });
            updateStatus('error', 'Missing connection configuration');
            return;
        }
        
        // Update status
        updateStatus('connecting', 'Requesting microphone permissions...');
        
        // Request microphone permission first
        try {
            await navigator.mediaDevices.getUserMedia({ audio: true });
            console.log('‚úÖ Microphone permission granted');
            updateStatus('connecting', 'Connecting to voice room...');
        } catch (permError) {
            console.error('‚ùå Microphone permission denied:', permError);
            updateStatus('error', 'Microphone permission required');
            return;
        }
        
        // Create room instance
        room = new LiveKitSDK.Room({
            // Adaptive stream for better performance
            adaptiveStream: true,
            // Automatic quality adjustment
            dynacast: true,
            // Log level for debugging
            logLevel: 'debug',
            // Audio capture settings - reduce aggressive filtering
            audioCaptureDefaults: {
                echoCancellation: true,
                noiseSuppression: false,  // Disable to prevent filtering speech
                autoGainControl: true,
                // Additional constraints to improve audio capture
                sampleRate: 48000,
                channelCount: 1
            },
            // Audio output settings
            audioOutput: {
                speakerOn: true
            }
        });
        
        // Store room reference globally for cleanup
        window.livekitRoom = room;
        
        // Set up event handlers
        room.on('connected', handleConnected);
        room.on('disconnected', handleDisconnected);
        room.on('participantConnected', handleParticipantConnected);
        room.on('participantDisconnected', handleParticipantDisconnected);
        room.on('activeSpeakersChanged', handleActiveSpeakers);
        room.on('localTrackPublished', handleLocalTrackPublished);
        room.on('trackSubscribed', handleTrackSubscribed);
        room.on('dataReceived', handleDataReceived);
        room.on('error', handleError);
        
        // Connect to room with timeout
        console.log('Attempting to connect to room...');
        console.log('Using LiveKit client version:', LiveKitSDK.version || 'unknown');
        const connectStart = Date.now();
        
        // Get actual values (in case template rendering fails)
        const serverUrl = '{{ server_url }}' || window.livekitServerUrl;
        const userToken = '{{ user_token }}' || window.livekitUserToken;
        
        console.log('Final connection params:', {
            serverUrl: serverUrl,
            userTokenLength: userToken ? userToken.length : 0,
            roomName: '{{ room_name }}'
        });
        
        // Try connection with detailed error handling
        try {
            await room.connect(serverUrl, userToken);
            const connectTime = Date.now() - connectStart;
            console.log(`‚úÖ Connection successful in ${connectTime}ms`);
        } catch (connectError) {
            console.error('‚ùå Connection failed:', connectError);
            console.error('Connection error type:', connectError.constructor.name);
            console.error('Connection error message:', connectError.message);
            
            // Provide more specific error messages
            if (connectError.message.includes('timeout')) {
                throw new Error('Connection timed out. Please check your network.');
            } else if (connectError.message.includes('unauthorized') || connectError.message.includes('401')) {
                throw new Error('Authentication failed. Invalid token.');
            } else if (connectError.message.includes('network') || connectError.message.includes('NETWORK')) {
                throw new Error('Network error. Please check your connection.');
            } else {
                throw connectError;
            }
        }
        
    } catch (error) {
        console.error('Failed to initialize LiveKit:', error);
        console.error('Error details:', {
            name: error.name,
            message: error.message,
            stack: error.stack
        });
        updateStatus('error', 'Failed to connect: ' + error.message);
    }
}

// Handle successful connection
async function handleConnected() {
    console.log('Connected to LiveKit room');
    updateStatus('connected', 'Connected to voice room');
    
    // Enable mute button
    document.getElementById('muteBtn').disabled = false;
    
    // Request microphone permission and publish audio
    try {
        console.log('üé§ Enabling microphone...');
        
        // Create custom microphone track with specific constraints
        try {
            // First, create a custom audio track with less aggressive processing
            const audioConstraints = {
                echoCancellation: true,
                noiseSuppression: false,  // Critical: disable noise suppression
                autoGainControl: true,
                // Additional constraints
                sampleRate: 48000,
                channelCount: 1,
                latency: 0,  // Minimize latency
                // Try to disable browser-level VAD if possible
                googAutoGainControl: true,
                googNoiseSuppression: false,
                googHighpassFilter: false,
                googEchoCancellation: true
            };
            
            // Get user media with our constraints
            const stream = await navigator.mediaDevices.getUserMedia({ 
                audio: audioConstraints 
            });
            
            console.log('üé§ Got custom audio stream:', stream);
            console.log('üé§ Audio track settings:', stream.getAudioTracks()[0].getSettings());
            
            // Create LiveKit LocalAudioTrack from our stream
            const localAudioTrack = await LiveKitSDK.createLocalAudioTrack({
                deviceId: stream.getAudioTracks()[0].getSettings().deviceId,
                echoCancellation: true,
                noiseSuppression: false,  // Critical: disable noise suppression
                autoGainControl: true,
            });
            
            // Publish with options that minimize silence detection
            const publishOptions = {
                dtx: false,  // Disable discontinuous transmission
                red: false,  // Disable redundancy encoding
                maxBitrate: 64000,
                // Force continuous transmission
                simulcast: false
            };
            
            // Publish the LiveKit track
            await room.localParticipant.publishTrack(localAudioTrack, publishOptions);
            console.log('‚úÖ Published custom audio track');
            
        } catch (customTrackError) {
            console.warn('Could not create custom track, falling back to default:', customTrackError);
            // Fallback to standard method
            await room.localParticipant.setMicrophoneEnabled(true);
        }
        
        // The audio track will be available via the localTrackPublished event
        // For immediate debugging, check the audio tracks if available
        console.log('üé§ Checking local participant audio tracks...');
        
        if (room.localParticipant.audioTracks) {
            try {
                const audioTracks = Array.from(room.localParticipant.audioTracks.values());
                console.log(`   - Found ${audioTracks.length} audio track(s)`);
                
                audioTracks.forEach((publication, index) => {
                    console.log(`   - Track ${index}:`, {
                        trackSid: publication.trackSid,
                        isMuted: publication.isMuted,
                        track: publication.track
                    });
                    
                    // Monitor audio levels if track is available
                    if (publication.track && publication.track.on) {
                        console.log('   - Setting up audio level monitoring...');
                        publication.track.on('audioLevelChanged', (level) => {
                            console.log(`üîä Audio level: ${level}`);
                        });
                    }
                });
            } catch (e) {
                console.log('   - Could not access audio tracks:', e.message);
                console.log('   - Audio tracks will be available in localTrackPublished event');
            }
        } else {
            console.log('   - audioTracks property not available yet');
            console.log('   - Audio track will be available via localTrackPublished event');
        }
        
        updateMicStatus('Microphone: Active');
        document.getElementById('audioLevelContainer').classList.remove('hidden');
    } catch (error) {
        console.error('Microphone error:', error);
        updateMicStatus('Microphone: ' + error.message);
    }
}

// Handle disconnection
function handleDisconnected() {
    console.log('Disconnected from LiveKit room');
    updateStatus('disconnected', 'Disconnected from voice room');
    document.getElementById('muteBtn').disabled = true;
}

// Handle participant connected (agent)
function handleParticipantConnected(participant) {
    console.log('Participant connected:', participant.identity);
    if (participant.identity.includes('agent')) {
        document.getElementById('agentStatus').classList.remove('hidden');
        updateStatus('agent-listening', 'Listening...');
    }
}

// Handle participant disconnected
function handleParticipantDisconnected(participant) {
    console.log('Participant disconnected:', participant.identity);
    if (participant.identity.includes('agent')) {
        document.getElementById('agentStatus').classList.add('hidden');
        updateStatus('connected', 'Agent disconnected');
    }
}

// Handle active speakers (audio level visualization)
function handleActiveSpeakers(speakers) {
    // Ensure speakers is an array
    if (!speakers || !Array.isArray(speakers)) {
        // If speakers is not an array, it might be undefined or in a different format
        console.log('Speakers parameter is not an array:', speakers);
        return;
    }
    
    // Update audio level for local participant
    const localSpeaker = speakers.find(s => s.identity === room.localParticipant.identity);
    const userSpeaking = localSpeaker && localSpeaker.audioLevel > 0.01;
    
    if (localSpeaker) {
        const level = Math.min(100, localSpeaker.audioLevel * 100);
        document.getElementById('audioLevel').style.width = level + '%';
    } else {
        document.getElementById('audioLevel').style.width = '0%';
    }
    
    // Check if agent is speaking
    const agentSpeaker = speakers.find(s => s.identity.includes('agent'));
    const agentSpeaking = agentSpeaker && agentSpeaker.audioLevel > 0.01;
    
    // Determine status based on who's speaking
    if (agentSpeaking) {
        // Agent is actively speaking
        updateStatus('agent-responding', 'Agent is speaking...');
    } else if (userSpeaking) {
        // User is speaking
        updateStatus('user-speaking', 'Listening to you...');
    } else {
        // No one is speaking - check if agent is still connected
        if (room && room.participants) {
            const hasAgent = Array.from(room.participants.values()).some(p => p.identity.includes('agent'));
            if (hasAgent) {
                updateStatus('agent-listening', 'Listening...');
            }
        }
    }
}

// Handle local track published
function handleLocalTrackPublished(publication) {
    console.log('üì° Local track published:', {
        kind: publication.kind,
        trackSid: publication.trackSid,
        trackName: publication.trackName,
        isMuted: publication.isMuted,
        track: publication.track
    });
    
    if (publication.kind === 'audio') {
        audioTrack = publication.track;
        console.log('üé§ Audio track published and stored');
        
        // Monitor audio levels
        if (audioTrack && audioTrack.on) {
            console.log('üìä Setting up audio level monitoring on published track...');
            
            let lastLogTime = 0;
            let silenceCount = 0;
            audioTrack.on('audioLevelChanged', (level) => {
                // Log every 500ms to avoid spam
                const now = Date.now();
                if (now - lastLogTime > 500) {
                    if (level < 0.01) {
                        silenceCount++;
                        console.log(`üîä Audio level: ${level.toFixed(4)} üî¥ SILENT (${silenceCount} detections)`);
                    } else {
                        silenceCount = 0;
                        console.log(`üîä Audio level: ${level.toFixed(4)} üü¢ ACTIVE`);
                    }
                    lastLogTime = now;
                }
            });
            
            // Monitor mute state
            audioTrack.on('muted', () => {
                console.log('üîá Track was muted by VAD/DTX');
            });
            
            audioTrack.on('unmuted', () => {
                console.log('üîä Track was unmuted');
            });
            
            // Also check the media stream track
            if (audioTrack.mediaStreamTrack) {
                console.log('üéôÔ∏è MediaStreamTrack settings:', audioTrack.mediaStreamTrack.getSettings());
                console.log('üéôÔ∏è MediaStreamTrack constraints:', audioTrack.mediaStreamTrack.getConstraints());
                
                // Set up Web Audio API analyzer for raw audio level monitoring
                setupAudioAnalyzer(audioTrack.mediaStreamTrack);
            }
        }
    }
}

// Handle track subscribed (receive audio from agent)
function handleTrackSubscribed(track, publication, participant) {
    console.log(`üîä Track subscribed from ${participant.identity}: ${track.kind}`);
    
    if (track.kind === 'audio') {
        console.log('‚úÖ Agent audio track received! Playing audio...');
        
        // Create audio element for playback
        const audioElement = document.createElement('audio');
        audioElement.id = `audio-${participant.identity}`;
        audioElement.autoplay = true;
        audioElement.style.display = 'none'; // Hidden audio element
        
        // Attach the track to the audio element
        track.attach(audioElement);
        
        // Add to page body
        document.body.appendChild(audioElement);
        
        console.log('üîä Agent audio playback started');
        
        // Don't immediately show "Agent is speaking" - wait for actual audio
        if (participant.identity.includes('agent')) {
            // Show that agent is listening
            updateStatus('agent-listening', 'Listening...');
        }
    }
}

// Handle data messages from agent
function handleDataReceived(payload, participant) {
    console.log('üì® Data received from:', participant?.identity, payload);
    
    try {
        const decoder = new TextDecoder();
        const message = JSON.parse(decoder.decode(payload));
        console.log('üìù Agent message:', message);
        
        if (message.type === 'agent_response') {
            // Display agent response in UI
            const statusText = document.getElementById('statusText');
            if (statusText) {
                statusText.textContent = `Agent: ${message.message}`;
                updateStatus('agent-responding', `Agent: ${message.message}`);
            }
            
            // Could also show in a dedicated chat area
            showAgentMessage(message.message);
        }
    } catch (error) {
        console.error('Error parsing agent message:', error);
    }
}

// Show agent message in UI
function showAgentMessage(message) {
    // Find or create a messages container
    let messagesContainer = document.getElementById('agentMessages');
    if (!messagesContainer) {
        messagesContainer = document.createElement('div');
        messagesContainer.id = 'agentMessages';
        messagesContainer.className = 'mt-4 p-3 bg-dark-elevated rounded-lg border border-dark-border';
        
        // Insert after the agent status div
        const agentStatus = document.getElementById('agentStatus');
        if (agentStatus && agentStatus.parentNode) {
            agentStatus.parentNode.insertBefore(messagesContainer, agentStatus.nextSibling);
        }
    }
    
    // Add the message
    const messageDiv = document.createElement('div');
    messageDiv.className = 'text-sm text-dark-text mb-2 p-2 bg-brand-teal/10 rounded border-l-2 border-brand-teal';
    messageDiv.innerHTML = `<strong>Agent:</strong> ${message}`;
    messagesContainer.appendChild(messageDiv);
    
    // Scroll to bottom
    messagesContainer.scrollTop = messagesContainer.scrollHeight;
    
    // Limit to last 5 messages
    const messages = messagesContainer.children;
    while (messages.length > 5) {
        messagesContainer.removeChild(messages[0]);
    }
}

// Handle errors
function handleError(error) {
    console.error('LiveKit error:', error);
    updateStatus('error', 'Error: ' + error.message);
}

// Toggle mute - expose to window for button onclick
window.toggleMute = function() {
    if (!room || !room.localParticipant) return;
    
    isMuted = !isMuted;
    room.localParticipant.setMicrophoneEnabled(!isMuted);
    
    const muteBtn = document.getElementById('muteBtn');
    const micIcon = muteBtn.querySelector('svg');
    
    if (isMuted) {
        muteBtn.classList.add('bg-brand-salmon');
        muteBtn.classList.remove('bg-dark-elevated');
        updateMicStatus('Microphone: Muted');
        // Update icon to muted
        micIcon.innerHTML = '<path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5.586 15L2 18.586V6a2 2 0 012-2h11a2 2 0 012 2v5M19 11v5a2 2 0 01-2 2h-7m-5 0h-.01"></path>';
    } else {
        muteBtn.classList.remove('bg-brand-salmon');
        muteBtn.classList.add('bg-dark-elevated');
        updateMicStatus('Microphone: Active');
        // Update icon to unmuted
        micIcon.innerHTML = '<path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"></path>';
    }
}

// Disconnect from voice - expose to window for button onclick
window.disconnectVoice = async function() {
    if (room) {
        await room.disconnect();
        room = null;
        window.livekitRoom = null;
    }
}

// Update connection status
function updateStatus(state, text) {
    const indicator = document.getElementById('statusIndicator');
    const statusText = document.getElementById('statusText');
    
    statusText.textContent = text;
    
    // Update indicator color based on state
    indicator.className = 'w-3 h-3 rounded-full ';
    switch(state) {
        case 'connecting':
            indicator.className += 'bg-yellow-500 animate-pulse';
            break;
        case 'connected':
            indicator.className += 'bg-green-500';
            break;
        case 'agent-connected':
            indicator.className += 'bg-brand-teal';
            break;
        case 'agent-listening':
            indicator.className += 'bg-brand-teal animate-pulse';
            break;
        case 'user-speaking':
            indicator.className += 'bg-blue-500 animate-pulse';
            break;
        case 'agent-responding':
            indicator.className += 'bg-brand-orange animate-pulse';
            break;
        case 'error':
        case 'disconnected':
            indicator.className += 'bg-red-500';
            break;
    }
}

// Update microphone status
function updateMicStatus(text) {
    document.getElementById('micStatus').textContent = text;
}

// Track if we've already initialized to prevent double initialization
let voicePreviewInitialized = false;

// Initialize function that can be called immediately
function initializeVoicePreview() {
    if (voicePreviewInitialized) {
        console.log('‚ö†Ô∏è Voice preview already initialized, skipping...');
        return;
    }
    voicePreviewInitialized = true;
    
    console.log('üöÄ Voice preview template loaded');
    console.log('üîç Checking LiveKit client availability...');
    
    // Function to check if LiveKit SDK is available
    function checkLiveKitSDK() {
        // Debug: Check what's actually available in window
        console.log('üîç Available global variables:', {
            LiveKitSDK: typeof window.LiveKitSDK,
            LivekitClient: typeof LivekitClient,
            LiveKit: typeof LiveKit,
            livekit: typeof livekit,
            windowLivekitClient: typeof window.LivekitClient,
            windowLiveKit: typeof window.LiveKit,
            windowLivekit: typeof window.livekit,
            livekitSDKLoaded: window.livekitSDKLoaded
        });
        
        return typeof window.LiveKitSDK !== 'undefined' ||
               typeof LivekitClient !== 'undefined' || 
               typeof LiveKit !== 'undefined' || 
               typeof livekit !== 'undefined' ||
               typeof window.LivekitClient !== 'undefined' || 
               typeof window.LiveKit !== 'undefined' || 
               typeof window.livekit !== 'undefined';
    }
    
    // Function to wait for SDK to be available
    function waitForSDK() {
        if (checkLiveKitSDK()) {
            console.log('‚úÖ LiveKit client found');
            initializeLiveKit();
        } else if (window.livekitSDKLoaded === false) {
            console.error('‚ùå LiveKit SDK failed to load');
            updateStatus('error', 'LiveKit SDK failed to load');
        } else {
            console.log('üîÑ Waiting for LiveKit SDK to load...');
            setTimeout(waitForSDK, 100); // Check every 100ms
        }
    }
    
    // Debug: Check if script tag is present
    const scriptTags = document.querySelectorAll('script[src*="livekit"]');
    console.log('üîç LiveKit script tags found:', scriptTags.length);
    scriptTags.forEach((tag, index) => {
        console.log(`Script ${index}:`, tag.src);
    });
    
    // Start checking for SDK availability
    waitForSDK();
}

// Initialize on DOMContentLoaded for regular page loads
document.addEventListener('DOMContentLoaded', initializeVoicePreview);

// Also initialize immediately for HTMX loads
if (document.readyState === 'complete' || document.readyState === 'interactive') {
    // DOM is already ready, initialize immediately (HTMX case)
    initializeVoicePreview();
}

// Close the IIFE
})();

// Cleanup on page unload - needs to be outside IIFE to access window.livekitRoom
window.addEventListener('beforeunload', function() {
    if (window.livekitRoom) {
        window.livekitRoom.disconnect();
    }
});
</script>